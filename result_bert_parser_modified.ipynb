{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "def parse_name(name):\n",
    "  name = name.lower()\n",
    "  name = re.sub(r'[0-9]*', '', name)\n",
    "  if 'loss' in name or 'entropy' in name:\n",
    "    return 'Others'\n",
    "  elif 'optimizer' in name or 'update' in name or 'adam' in name:\n",
    "    return 'OPT'\n",
    "  elif 'layernorm' in name or 'layer_norm' in name or 'norm' in name:\n",
    "    return 'LayerNorm + Dropout'\n",
    "  elif 'batchnorm' in name or 'batch_norm' in name or 'relu' in name:\n",
    "    return 'BN+ReLU'\n",
    "  # elif 'cast' in name:\n",
    "  #   return 'Fusion(Cast)'\n",
    "  elif 'dropout' in name and 'self' in name or '/type_embeddings/matmul' in name:\n",
    "    return 'Softmax + Dropout'\n",
    "  elif 'dropout' in name :\n",
    "    return 'LayerNorm + Dropout'\n",
    "  elif 'relu' in name:\n",
    "    return 'Fusion(ReLU)'\n",
    "  elif 'softmax' in name:\n",
    "    return 'Softmax + Dropout'\n",
    "  return 'Fusion'\n",
    "\n",
    "def find_kernel_metadata(name, hlo_file_name):\n",
    "  if len(name.split('_')) == 1:\n",
    "    return name\n",
    "  name = name.replace('_', '.') + ' '\n",
    "  with open(hlo_file_name, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "      if name in line:\n",
    "        find_meta = line.split('metadata')\n",
    "        if len(find_meta) > 1 and len(find_meta[1].split('\\\"')) > 3:\n",
    "          name1 =find_meta[1].split('\\\"')[3]\n",
    "          name1 = parse_name(name1)\n",
    "#           if name1 == 'Fusion':\n",
    "#             print(name, find_meta[1].split('\\\"')[3])\n",
    "          return name1\n",
    "    return 'Fusion'\n",
    "\n",
    "namespace = ['CONV+BN+ELEMWISE', 'NDP_OP', 'BN+ELEMWISE', 'CONV', 'FC', 'POOLING', 'dxCONV', 'dwCONV', 'dxFC', 'dwFC', 'OPT',\\\n",
    "        'Fusion(Loss)', 'Fusion(Optimizer)', 'Fusion(LayerNorm)','Fusion(BatchNorm)', 'Fusion(Cast)', 'Fusion(Dropout)',\\\n",
    "        'Fusion(Einsum)', 'Fusion(BiasAdd)', 'Fusion(Gelu)', 'Fusion(ReLU)', 'Fusion(SelfAttention)', 'BN+ReLU', 'Fusion(Softmax)', 'LayerNorm',\n",
    "        'GEMM', 'Dropout', 'LayerNorm + Dropout', 'Softmax+Dropout']\n",
    "\n",
    "def setup_dataframe(df):\n",
    "   # df.to_csv('./before.csv')   \n",
    "\n",
    "   # namespace = ['fusion', 'elementwise', 'GEMM', 'CONV', 'Dgrad', 'Wgrad' ,'others']\n",
    "   compute_intensives = ['GEMM', 'CONV', 'Wgrad', 'Dgrad']\n",
    "   df['NAME'] = df['NAME'].replace('fusion.*', 'fusion', regex=True)\\\n",
    "                                       .replace('dgemm', 'GEMM', regex=True)\\\n",
    "                                       .replace('wgemm', 'GEMM', regex=True)\\\n",
    "                                       .replace('.*MetaKernel.*', 'elementwise', regex=True)\\\n",
    "                                       .replace('.*add.*', 'elementwise', regex=True)\\\n",
    "                                       .replace('.*mul.*', 'elementwise', regex=True)\\\n",
    "                                       .replace('.*log.*', 'elementwise', regex=True)\\\n",
    "                                       .replace('.*gemm_.*_tn', 'GEMM' , regex=True)\\\n",
    "                                       .replace('.*gemm_.*_nt', 'GEMM', regex=True)\\\n",
    "                                       .replace('.*dgrad.*', 'dxCONV', regex=True)\\\n",
    "                                       .replace('.*wgrad.*', 'dwCONV', regex=True)\\\n",
    "                                       .replace('.*1688cudnn.*', 'CONV+BN+ELEMWISE', regex=True)\\\n",
    "                                       .replace('.*convol.*', 'CONV+BN+ELEMWISE', regex=True)\\\n",
    "                                       .replace('.*gemm_.*', 'GEMM', regex=True)\\\n",
    "                                       .replace('gemm', 'GEMM', regex=True)\\\n",
    "                                       .replace('conv', 'CONV', regex=True)\\\n",
    "                                       .replace('.*conv2d.*', 'CONV+BN+ELEMWISE', regex=True)\\\n",
    "                                       .replace('.*first_layer.*', \"CONV+BN+ELEMWISE\", regex=True)\\\n",
    "                                       .replace('pool', \"POOLING\", regex=True)\\\n",
    "                                       .replace('.*c1_k1.*', \"CONV+BN+ELEMWISE\", regex=True)\\\n",
    "                                       .replace('.*bn.*', \"BN+ELEMWISE\", regex=True)\\\n",
    "                                       .replace('.*adam*', \"OPT\", regex=True)\n",
    "  \n",
    "\n",
    "\n",
    "   df['CONFIG'] = df['CONFIG'].replace('NDPX_baseline_64', 'NDPX_wc64')                 \n",
    "   df.loc[~df['NAME'].isin(namespace), 'NAME'] = 'Others'\n",
    "   df.loc[df['CYCLE'] == '  NOT FOUND', 'CYCLE'] = '0'\n",
    "   \n",
    "   \n",
    "   return df\n",
    "\n",
    "def setup_dataframe_baseline(df, hlo_path):\n",
    "   compute_intensives = ['GEMM', 'CONV', 'Wgrad', 'Dgrad']\n",
    "   \n",
    "\n",
    "\n",
    "   df['NAME'] = df['NAME'].replace('dgemm', 'dxFC', regex=True)\\\n",
    "                                       .replace('wgemm', 'GEMM', regex=True)\\\n",
    "                                       .replace('.*MetaKernel.*', 'elementwise', regex=True)\\\n",
    "                                       .replace('.*add.*', 'elementwise', regex=True)\\\n",
    "                                       .replace('.*mul.*', 'elementwise', regex=True)\\\n",
    "                                       .replace('.*log.*', 'elementwise', regex=True)\\\n",
    "                                       .replace('.*gemm_.*_tn', 'GEMM' , regex=True)\\\n",
    "                                       .replace('.*gemm_.*_nt', 'GEMM', regex=True)\\\n",
    "                                       .replace('.*dgrad.*', 'dxCONV', regex=True)\\\n",
    "                                       .replace('.*wgrad.*', 'dwCONV', regex=True)\\\n",
    "                                       .replace('.*1688cudnn.*', 'CONV', regex=True)\\\n",
    "                                       .replace('.*convol.*', 'CONV', regex=True)\\\n",
    "                                       .replace('.*gemm_.*', 'GEMM', regex=True)\\\n",
    "                                       .replace('gemm', 'GEMM', regex=True)\\\n",
    "                                       .replace('conv', 'CONV', regex=True)\\\n",
    "                                       .replace('.*conv2d.*', 'CONV', regex=True)\\\n",
    "                                       .replace('.*first_layer.*', \"CONV\", regex=True)\\\n",
    "                                       .replace('pool', \"POOLING\", regex=True)\\\n",
    "                                       .replace('.*c1_k1.*', \"CONV\", regex=True)\\\n",
    "                                       .replace('.*bn.*', \"BN+ELEMWISE\", regex=True)\\\n",
    "                                       .replace('.*adam*', \"OPT\", regex=True)\n",
    "                                   \n",
    "   fusions = df.loc[~df['NAME'].isin(namespace), 'NAME']\n",
    "   for fusion in fusions:\n",
    "      opname = find_kernel_metadata(fusion, hlo_path)\n",
    "      df.loc[df['NAME'] == fusion, 'NAME'] = opname                                 \n",
    " \n",
    "   df.loc[~df['NAME'].isin(namespace), 'NAME'] = 'Others'\n",
    "   df.loc[df['CYCLE'] == '  NOT FOUND', 'CYCLE'] = '0'\n",
    "   df.to_csv('./after.csv')\n",
    "   return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       CYCLE\n",
      "CONFIG   GPUS  NAME                         \n",
      "BASELINE 1_GPU GEMM                 26578592\n",
      "               LayerNorm + Dropout   2368218\n",
      "               OPT                  11837881\n",
      "               Others               11331217\n",
      "               Softmax+Dropout       7713032\n",
      "                                       CYCLE\n",
      "CONFIG   GPUS  NAME                         \n",
      "BASELINE 1_GPU GEMM                 60659096\n",
      "               LayerNorm + Dropout   6596630\n",
      "               OPT                  21465303\n",
      "               Others               21210773\n",
      "               Softmax+Dropout      23130172\n",
      "                                         CYCLE\n",
      "CONFIG   GPUS  NAME                           \n",
      "BASELINE 1_GPU GEMM                 17040252.0\n",
      "               LayerNorm + Dropout   2114206.0\n",
      "               OPT                   4813711.0\n",
      "               Others                4939778.0\n",
      "               Softmax+Dropout       7708570.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = [ 4] # [16,64]\n",
    "models = ['BERT_large_3_b']\n",
    "single_models = ['BERT_large_1_b']\n",
    "# models = ['resnet18']\n",
    "sync = ['nosync']\n",
    "GPUs = [2]\n",
    "config = 'NDPX_baseline_64'\n",
    "NDPX_MIDDLE_ENCODER_FW_START = 11 \n",
    "NDPX_MIDDLE_ENCODER_FW_END = 19\n",
    "NDPX_MIDDLE_ENCODER_BW_START = 42 \n",
    "NDPX_MIDDLE_ENCODER_BW_END = 50\n",
    "# BASELINE_MIDDLE_ENCODER_FW_START = 8 \n",
    "# BASELINE_MIDDLE_ENCODER_FW_END = 13\n",
    "# BASELINE_MIDDLE_ENCODER_BW_START = 30 \n",
    "# BASELINE_MIDDLE_ENCODER_BW_END = 35\n",
    "N_ENCODERS = 24\n",
    "for model, single_model in zip(models, single_models):\n",
    "   total_result = pd.DataFrame()\n",
    "\n",
    "\n",
    "   for b in batch_size:\n",
    "      ndpx_file_paths = []\n",
    "      baseline_home='/home/shared/CXL_memory_buffer/BASELINE_ISCA/csv_files/'\n",
    "      baseline_path_3=baseline_home+model+str(b)+'-NDPX_baseline_64.csv'\n",
    "      baseline_path_single=baseline_home+single_model+str(b)+'-NDPX_baseline_64.csv'\n",
    "\n",
    "      for GPU in GPUs:\n",
    "         for s in sync:\n",
    "            if GPU == 1 and s == 'sync':\n",
    "               continue\n",
    "            temp = 1\n",
    "            if GPU == 8:\n",
    "               temp = 8\n",
    "            ndp_csv_home='/home/shared/CXL_memory_buffer/NDP_ISCA/csv_files/'\n",
    "            file_path=ndp_csv_home + model + str(b)+'-'+ config + '-'+str(GPU)+'-' + str(GPU) + '-'+s+'.csv'\n",
    "            file_path_bw=ndp_csv_home + model + str(b)+'-'+ config + '-'+str(GPU)+'-' + str(GPU) + '-' +s+'-bw.csv'\n",
    "            ndpx_file_paths.append(file_path)\n",
    "            ndpx_file_paths.append(file_path_bw)\n",
    "\n",
    "      baseline_3 = pd.read_csv(baseline_path_3)\n",
    "      baseline_3['GPUS'] = '1_GPU'\n",
    "      baseline_3['CONFIG'] = 'BASELINE'\n",
    "      baseline_1 = pd.read_csv(baseline_path_single)\n",
    "      baseline_1['GPUS'] = '1_GPU'\n",
    "      baseline_1['CONFIG'] = 'BASELINE'\n",
    "      baseline_hlp_path=baseline_home+'xla_hlo/'+model+str(b)+'.txt'\n",
    "      baseline_3 = setup_dataframe_baseline(baseline_3, baseline_hlp_path)\n",
    "      baseline_3['CYCLE'] = pd.to_numeric(baseline_3['CYCLE'])\n",
    "      baseline_3_hops = pd.read_csv(f'/home/shared/CXL_memory_buffer/BASELINE_ISCA/traces/{model}{str(b)}/kernelslist.g.hops')\n",
    "      baseline_3 = pd.merge(baseline_3, baseline_3_hops, how='left', on='ID')\n",
    "      baseline_3.loc[baseline_3.HOPS > 20, 'DIRECTION'] = 'backward'\n",
    "      baseline_3.loc[baseline_3.HOPS <= 20, 'DIRECTION'] = 'forward'\n",
    "      baseline_hlp_path=baseline_home+'xla_hlo/'+single_model+str(b)+'.txt'\n",
    "      baseline_1 = setup_dataframe_baseline(baseline_1, baseline_hlp_path)\n",
    "      baseline_1['CYCLE'] = pd.to_numeric(baseline_1['CYCLE'])\n",
    "\n",
    "\n",
    "      baseline_1 = baseline_1.groupby(['CONFIG','GPUS','NAME']).sum()[[ 'CYCLE']] \n",
    "      baseline_3 = baseline_3.groupby(['CONFIG','GPUS','NAME']).sum()[[ 'CYCLE']]\n",
    "      print(baseline_1)\n",
    "      print(baseline_3)\n",
    "\n",
    "      baseline_large = baseline_3 - baseline_1\n",
    "      print(baseline_large/2)\n",
    "#       mask = baseline_large.CYCLE < 0\n",
    "#       baseline_large.loc[mask, 'CYCLE'] = 0\n",
    "#       df = (baseline_large / 2 ) * (N_ENCODERS - 1) + baseline_1\n",
    "\n",
    "#       ndpx_hops = pd.read_csv(f'/home/shared/CXL_memory_buffer/NDP_ISCA/traces/{model}{str(b)}/kernelslist.g.hops')\n",
    "#       ndpx = pd.read_csv(ndpx_file_paths[0])\n",
    "#       ndpx = pd.concat([ndpx, pd.read_csv(ndpx_file_paths[1])])\n",
    "#       ndpx = pd.merge(ndpx, ndpx_hops, how='left', on='ID')\n",
    "#       ndpx['GPUS'] = ndpx_file_paths[0].split('-')[-2]+'_GPU'\n",
    "\n",
    "\n",
    "\n",
    "#       for i in range(1,len(GPUs)):\n",
    "#           ndpx1 = pd.read_csv(ndpx_file_paths[2*i])\n",
    "#           ndpx1 = pd.concat([ndpx1, pd.read_csv(ndpx_file_paths[2*i+1])])\n",
    "#           ndpx1 = pd.merge(ndpx1, ndpx_hops, how='left', on='ID')\n",
    "#           ndpx1['GPUS'] = ndpx_file_paths[2*i].split('-')[-2]+'_GPU'\n",
    "#           ndpx = pd.concat([ndpx, ndpx1])\n",
    "        \n",
    "#       ndpx = setup_dataframe(ndpx)\n",
    "#       print(ndpx)\n",
    "#       ndpx['CYCLE'] = pd.to_numeric(ndpx['CYCLE'])\n",
    "#       ndpx.loc[ndpx.HOPS > 29, 'DIRECTION'] = 'backward'\n",
    "#       ndpx.loc[ndpx.HOPS <= 29, 'DIRECTION'] = 'forward'\n",
    "#       ndpx.loc[(ndpx.HOPS >= NDPX_MIDDLE_ENCODER_FW_START) & (ndpx.HOPS <= NDPX_MIDDLE_ENCODER_FW_END), 'CYCLE'] *= (N_ENCODERS -2)\n",
    "#       ndpx.loc[(ndpx.HOPS >= NDPX_MIDDLE_ENCODER_BW_START) & (ndpx.HOPS <= NDPX_MIDDLE_ENCODER_BW_END), 'CYCLE'] *= (N_ENCODERS -2)\n",
    "#       ndpx.loc[(ndpx.HOPS == 0) & (ndpx.HOPS != ndpx.ID.min()), 'CYCLE'] = 0\n",
    "\n",
    "#       grouped = ndpx.groupby(['CONFIG','GPUS','NAME', \"DIRECTION\"]).sum()[[ 'CYCLE']] \n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "#       baseline_runtime = pd.to_numeric(df['CYCLE']).sum()\n",
    "      \n",
    "#       df = pd.concat([df, grouped])\n",
    "#       df['BATCH'] = b\n",
    "#       total_result = pd.concat([total_result, df])\n",
    "#       df.to_csv('./outputs/'+model+'_grouped_value-'+str(b)+'.csv')\n",
    "#       normalized = df\n",
    "#       normalized['CYCLE'] = df['CYCLE'] / baseline_runtime\n",
    "#       normalized.to_csv('./outputs/'+model+'_total_normalized2-'+str(b)+'.csv')\n",
    "\n",
    "#    total_result.to_csv(f'./outputs/{model}_total_batches.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       CYCLE\n",
      "CONFIG   GPUS  NAME                         \n",
      "BASELINE 1_GPU GEMM                 19894657\n",
      "               LayerNorm + Dropout   1336870\n",
      "               OPT                  11861687\n",
      "               Others                7785233\n",
      "               Softmax+Dropout       3943396\n",
      "                                       CYCLE\n",
      "CONFIG   GPUS  NAME                         \n",
      "BASELINE 1_GPU GEMM                 40291960\n",
      "               LayerNorm + Dropout   3562004\n",
      "               OPT                  21400534\n",
      "               Others               13543766\n",
      "               Softmax+Dropout      11825154\n",
      "                                         CYCLE\n",
      "CONFIG   GPUS  NAME                           \n",
      "BASELINE 1_GPU GEMM                 10198651.5\n",
      "               LayerNorm + Dropout   1112567.0\n",
      "               OPT                   4769423.5\n",
      "               Others                2879266.5\n",
      "               Softmax+Dropout       3940879.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = [2] # [16,64]\n",
    "models = ['BERT_large_3_b']\n",
    "single_models = ['BERT_large_1_b']\n",
    "# models = ['resnet18']\n",
    "sync = ['nosync']\n",
    "GPUs = [2]\n",
    "config = 'NDPX_baseline_64'\n",
    "NDPX_MIDDLE_ENCODER_FW_START = 11 \n",
    "NDPX_MIDDLE_ENCODER_FW_END = 19\n",
    "NDPX_MIDDLE_ENCODER_BW_START = 42 \n",
    "NDPX_MIDDLE_ENCODER_BW_END = 50\n",
    "# BASELINE_MIDDLE_ENCODER_FW_START = 8 \n",
    "# BASELINE_MIDDLE_ENCODER_FW_END = 13\n",
    "# BASELINE_MIDDLE_ENCODER_BW_START = 30 \n",
    "# BASELINE_MIDDLE_ENCODER_BW_END = 35\n",
    "N_ENCODERS = 24\n",
    "for model, single_model in zip(models, single_models):\n",
    "   total_result = pd.DataFrame()\n",
    "\n",
    "\n",
    "   for b in batch_size:\n",
    "      ndpx_file_paths = []\n",
    "      baseline_home='/home/shared/CXL_memory_buffer/BASELINE_ISCA/csv_files/'\n",
    "      baseline_path_3=baseline_home+model+str(b)+'-NDPX_baseline_64.csv'\n",
    "      baseline_path_single=baseline_home+single_model+str(b)+'-NDPX_baseline_64.csv'\n",
    "\n",
    "      for GPU in GPUs:\n",
    "         for s in sync:\n",
    "            if GPU == 1 and s == 'sync':\n",
    "               continue\n",
    "            temp = 1\n",
    "            if GPU == 8:\n",
    "               temp = 8\n",
    "            ndp_csv_home='/home/shared/CXL_memory_buffer/NDP_ISCA/csv_files/'\n",
    "            file_path=ndp_csv_home + model + str(b)+'-'+ config + '-'+str(GPU)+'-' + str(GPU) + '-'+s+'.csv'\n",
    "            file_path_bw=ndp_csv_home + model + str(b)+'-'+ config + '-'+str(GPU)+'-' + str(GPU) + '-' +s+'-bw.csv'\n",
    "            ndpx_file_paths.append(file_path)\n",
    "            ndpx_file_paths.append(file_path_bw)\n",
    "\n",
    "      baseline_3 = pd.read_csv(baseline_path_3)\n",
    "      baseline_3['GPUS'] = '1_GPU'\n",
    "      baseline_3['CONFIG'] = 'BASELINE'\n",
    "      baseline_1 = pd.read_csv(baseline_path_single)\n",
    "      baseline_1['GPUS'] = '1_GPU'\n",
    "      baseline_1['CONFIG'] = 'BASELINE'\n",
    "      baseline_hlp_path=baseline_home+'xla_hlo/'+model+str(b)+'.txt'\n",
    "      baseline_3 = setup_dataframe_baseline(baseline_3, baseline_hlp_path)\n",
    "      baseline_3['CYCLE'] = pd.to_numeric(baseline_3['CYCLE'])\n",
    "      baseline_3_hops = pd.read_csv(f'/home/shared/CXL_memory_buffer/BASELINE_ISCA/traces/{model}{str(b)}/kernelslist.g.hops')\n",
    "      baseline_3 = pd.merge(baseline_3, baseline_3_hops, how='left', on='ID')\n",
    "      baseline_3.loc[baseline_3.HOPS > 20, 'DIRECTION'] = 'backward'\n",
    "      baseline_3.loc[baseline_3.HOPS <= 20, 'DIRECTION'] = 'forward'\n",
    "      baseline_hlp_path=baseline_home+'xla_hlo/'+single_model+str(b)+'.txt'\n",
    "      baseline_1 = setup_dataframe_baseline(baseline_1, baseline_hlp_path)\n",
    "      baseline_1['CYCLE'] = pd.to_numeric(baseline_1['CYCLE'])\n",
    "\n",
    "\n",
    "      baseline_1 = baseline_1.groupby(['CONFIG','GPUS','NAME']).sum()[[ 'CYCLE']] \n",
    "      baseline_3 = baseline_3.groupby(['CONFIG','GPUS','NAME']).sum()[[ 'CYCLE']]\n",
    "      print(baseline_1)\n",
    "      print(baseline_3)\n",
    "\n",
    "      baseline_large = baseline_3 - baseline_1\n",
    "      print(baseline_large/2)\n",
    "#       mask = baseline_large.CYCLE < 0\n",
    "#       baseline_large.loc[mask, 'CYCLE'] = 0\n",
    "#       df = (baseline_large / 2 ) * (N_ENCODERS - 1) + baseline_1\n",
    "\n",
    "#       ndpx_hops = pd.read_csv(f'/home/shared/CXL_memory_buffer/NDP_ISCA/traces/{model}{str(b)}/kernelslist.g.hops')\n",
    "#       ndpx = pd.read_csv(ndpx_file_paths[0])\n",
    "#       ndpx = pd.concat([ndpx, pd.read_csv(ndpx_file_paths[1])])\n",
    "#       ndpx = pd.merge(ndpx, ndpx_hops, how='left', on='ID')\n",
    "#       ndpx['GPUS'] = ndpx_file_paths[0].split('-')[-2]+'_GPU'\n",
    "\n",
    "\n",
    "\n",
    "#       for i in range(1,len(GPUs)):\n",
    "#           ndpx1 = pd.read_csv(ndpx_file_paths[2*i])\n",
    "#           ndpx1 = pd.concat([ndpx1, pd.read_csv(ndpx_file_paths[2*i+1])])\n",
    "#           ndpx1 = pd.merge(ndpx1, ndpx_hops, how='left', on='ID')\n",
    "#           ndpx1['GPUS'] = ndpx_file_paths[2*i].split('-')[-2]+'_GPU'\n",
    "#           ndpx = pd.concat([ndpx, ndpx1])\n",
    "        \n",
    "#       ndpx = setup_dataframe(ndpx)\n",
    "#       print(ndpx)\n",
    "#       ndpx['CYCLE'] = pd.to_numeric(ndpx['CYCLE'])\n",
    "#       ndpx.loc[ndpx.HOPS > 29, 'DIRECTION'] = 'backward'\n",
    "#       ndpx.loc[ndpx.HOPS <= 29, 'DIRECTION'] = 'forward'\n",
    "#       ndpx.loc[(ndpx.HOPS >= NDPX_MIDDLE_ENCODER_FW_START) & (ndpx.HOPS <= NDPX_MIDDLE_ENCODER_FW_END), 'CYCLE'] *= (N_ENCODERS -2)\n",
    "#       ndpx.loc[(ndpx.HOPS >= NDPX_MIDDLE_ENCODER_BW_START) & (ndpx.HOPS <= NDPX_MIDDLE_ENCODER_BW_END), 'CYCLE'] *= (N_ENCODERS -2)\n",
    "#       ndpx.loc[(ndpx.HOPS == 0) & (ndpx.HOPS != ndpx.ID.min()), 'CYCLE'] = 0\n",
    "\n",
    "#       grouped = ndpx.groupby(['CONFIG','GPUS','NAME', \"DIRECTION\"]).sum()[[ 'CYCLE']] \n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "#       baseline_runtime = pd.to_numeric(df['CYCLE']).sum()\n",
    "      \n",
    "#       df = pd.concat([df, grouped])\n",
    "#       df['BATCH'] = b\n",
    "#       total_result = pd.concat([total_result, df])\n",
    "#       df.to_csv('./outputs/'+model+'_grouped_value-'+str(b)+'.csv')\n",
    "#       normalized = df\n",
    "#       normalized['CYCLE'] = df['CYCLE'] / baseline_runtime\n",
    "#       normalized.to_csv('./outputs/'+model+'_total_normalized2-'+str(b)+'.csv')\n",
    "\n",
    "#    total_result.to_csv(f'./outputs/{model}_total_batches.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jueonpark/tracegen/csv_files/bert_large_cost_model2/kernelslist.g.hops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1124ae74f6a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mndpx_file_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path_bw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0mndpx_hops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/home/jueonpark/tracegen/csv_files/{model}{str(b)}/kernelslist.g.hops'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m       \u001b[0mndpx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndpx_file_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mndpx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mndpx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndpx_file_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cxl_xla/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cxl_xla/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cxl_xla/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cxl_xla/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cxl_xla/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jueonpark/tracegen/csv_files/bert_large_cost_model2/kernelslist.g.hops'"
     ]
    }
   ],
   "source": [
    "# for ndpx results\n",
    "batch_size = [2] # [16,64]\n",
    "models = ['bert_large_cost_model']\n",
    "single_models = ['BERT_large_1_b']\n",
    "sync = ['nosync']\n",
    "GPUs = [1]\n",
    "config = 'NDPX_baseline_64'\n",
    "NDPX_MIDDLE_ENCODER_FW_START = 11 \n",
    "NDPX_MIDDLE_ENCODER_FW_END = 19\n",
    "NDPX_MIDDLE_ENCODER_BW_START = 42 \n",
    "NDPX_MIDDLE_ENCODER_BW_END = 50\n",
    "\n",
    "N_ENCODERS = 24\n",
    "for model, single_model in zip(models, single_models):\n",
    "   total_result = pd.DataFrame()\n",
    "\n",
    "\n",
    "   for b in batch_size:\n",
    "      ndpx_file_paths = []\n",
    "      baseline_home='/home/jueonpark/tracegen/csv_files/'\n",
    "      baseline_path_3=baseline_home+model+str(b)+'-NDPX_baseline_64.csv'\n",
    "      baseline_path_single=baseline_home+single_model+str(b)+'-NDPX_baseline_64.csv'\n",
    "\n",
    "      for GPU in GPUs:\n",
    "         for s in sync:\n",
    "            if GPU == 1 and s == 'sync':\n",
    "               continue\n",
    "            temp = 1\n",
    "            if GPU == 8:\n",
    "               temp = 8\n",
    "            ndp_csv_home='/home/shared/CXL_memory_buffer/NDP_ISCA/csv_files/'\n",
    "            file_path=ndp_csv_home + model + str(b)+'-'+ config + '-'+str(GPU)+'-' + str(GPU) + '-'+s+'.csv'\n",
    "            file_path_bw=ndp_csv_home + model + str(b)+'-'+ config + '-'+str(GPU)+'-' + str(GPU) + '-' +s+'-bw.csv'\n",
    "            ndpx_file_paths.append(file_path)\n",
    "            ndpx_file_paths.append(file_path_bw)\n",
    "\n",
    "      ndpx_hops = pd.read_csv(f'/home/jueonpark/tracegen/csv_files/{model}{str(b)}/kernelslist.g.hops')\n",
    "      ndpx = pd.read_csv(ndpx_file_paths[0])\n",
    "      ndpx = pd.concat([ndpx, pd.read_csv(ndpx_file_paths[1])])\n",
    "      ndpx = pd.merge(ndpx, ndpx_hops, how='left', on='ID')\n",
    "      ndpx['GPUS'] = ndpx_file_paths[0].split('-')[-2]+'_GPU'\n",
    "\n",
    "\n",
    "      for i in range(1,len(GPUs)):\n",
    "          ndpx1 = pd.read_csv(ndpx_file_paths[2*i])\n",
    "          ndpx1 = pd.concat([ndpx1, pd.read_csv(ndpx_file_paths[2*i+1])])\n",
    "          ndpx1 = pd.merge(ndpx1, ndpx_hops, how='left', on='ID')\n",
    "          ndpx1['GPUS'] = ndpx_file_paths[2*i].split('-')[-2]+'_GPU'\n",
    "          ndpx = pd.concat([ndpx, ndpx1])\n",
    "        \n",
    "      ndpx = setup_dataframe(ndpx)\n",
    "      print(ndpx)\n",
    "      ndpx['CYCLE'] = pd.to_numeric(ndpx['CYCLE'])\n",
    "      ndpx.loc[ndpx.HOPS > 29, 'DIRECTION'] = 'backward'\n",
    "      ndpx.loc[ndpx.HOPS <= 29, 'DIRECTION'] = 'forward'\n",
    "      ndpx.loc[(ndpx.HOPS >= NDPX_MIDDLE_ENCODER_FW_START) & (ndpx.HOPS <= NDPX_MIDDLE_ENCODER_FW_END), 'CYCLE'] *= (N_ENCODERS -2)\n",
    "      ndpx.loc[(ndpx.HOPS >= NDPX_MIDDLE_ENCODER_BW_START) & (ndpx.HOPS <= NDPX_MIDDLE_ENCODER_BW_END), 'CYCLE'] *= (N_ENCODERS -2)\n",
    "      ndpx.loc[(ndpx.HOPS == 0) & (ndpx.HOPS != ndpx.ID.min()), 'CYCLE'] = 0\n",
    "\n",
    "      grouped = ndpx.groupby(['CONFIG','GPUS','NAME', \"DIRECTION\"]).sum()[[ 'CYCLE']] \n",
    "\n",
    "\n",
    "\n",
    "      baseline_runtime = pd.to_numeric(df['CYCLE']).sum()\n",
    "      \n",
    "      df = pd.concat([df, grouped])\n",
    "      df['BATCH'] = b\n",
    "      total_result = pd.concat([total_result, df])\n",
    "      df.to_csv('./outputs/'+model+'_grouped_value-'+str(b)+'.csv')\n",
    "      normalized = df\n",
    "      normalized['CYCLE'] = df['CYCLE'] / baseline_runtime\n",
    "      normalized.to_csv('./outputs/'+model+'_total_normalized2-'+str(b)+'.csv')\n",
    "\n",
    "   total_result.to_csv(f'./outputs/{model}_total_batches.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fab24b6b85560413696bc1c2c0d0902d870397ba827e16b10da0b7a8dd59ba0"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('cxl_xla')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
